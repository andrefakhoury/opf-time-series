{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b26fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from dtaidistance import dtw\n",
    "from src.utils import error, read_df\n",
    "from operator import itemgetter\n",
    "from src.OPFClassifier import DSU\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import heapq\n",
    "from sklearn.manifold import MDS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e048feb",
   "metadata": {},
   "source": [
    "### Changing Kruskral to Prim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dce8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optimum Path Forest Classifier\"\"\"\n",
    "class OptimumPathForestClassifierPrim:\n",
    "    def __init__(self, cost='euclidean-distance'):\n",
    "        available_cost_functions = {\n",
    "            'euclidean-distance': lambda x, y: np.linalg.norm(x - y),\n",
    "            'manhattan-distance': lambda x, y: np.sum(np.abs(x - y)),\n",
    "            'dtw-distance': lambda x, y: dtw.distance_fast(x, y, window=100, use_pruning=True)\n",
    "        }\n",
    "        assert cost in available_cost_functions.keys(),\\\n",
    "            f\"Invalid cost function. Should be one of {available_cost_functions.keys()}\"\n",
    "        self.F = available_cost_functions[cost]\n",
    "    \n",
    "    def find_prototypes(self, adj, Y):\n",
    "        prototypes = []\n",
    "        pq = [[0., 0, -1]]\n",
    "        heapq.heapify(pq)\n",
    "        \n",
    "        cost = np.ones(len(adj)) * np.inf\n",
    "        cost[0] = 0.\n",
    "        while pq:\n",
    "            u_w, u, p = heapq.heappop(pq)\n",
    "            if u_w < cost[u]: continue\n",
    "            cost[u] = 0.\n",
    "                \n",
    "            # Edge p->u is a part of MST.\n",
    "            if p != -1 and Y[u] != Y[p]:\n",
    "                prototypes += [u, v]\n",
    "\n",
    "            for v, w in adj[u]:\n",
    "                if cost[v] > w:\n",
    "                    cost[v] = w\n",
    "                    heapq.heappush(pq, [w, v, u])\n",
    "        return list(np.unique(prototypes))\n",
    "    \n",
    "    def fit(self, X_, Y_):\n",
    "        n = len(Y_)\n",
    "        self.X = np.array(X_, copy=True, dtype=float)\n",
    "        self.label = np.ones(n, dtype=int) * -1\n",
    "        Y = np.array(Y_, copy=True, dtype=int)\n",
    "        \n",
    "        # First of all, builds the graph\n",
    "        adj = defaultdict(list)\n",
    "        for u in range(n):\n",
    "            adj[u] = [(int(v), self.F(self.X[u], self.X[v])) for v in range(n)]\n",
    "            \n",
    "        # Runs MST (Prim) to choose PROTOTYPES (seed vertices)\n",
    "        self.prototypes = self.find_prototypes(adj, Y)\n",
    "        \n",
    "        # Run multisourced dijkstra on prototypes to get the cost\n",
    "        self.cost = np.ones(n) * np.inf\n",
    "        self.cost[self.prototypes] = 0\n",
    "        self.label[self.prototypes] = Y[self.prototypes]\n",
    "        \n",
    "        pq = [[0., u] for u in self.prototypes]\n",
    "        heapq.heapify(pq)\n",
    "        while pq:\n",
    "            u_w, u = heapq.heappop(pq)\n",
    "            if self.cost[u] < u_w:\n",
    "                continue\n",
    "            for v, w in adj[u]:\n",
    "                if self.cost[v] > max(u_w, w):\n",
    "                    self.cost[v] = max(u_w, w)\n",
    "                    self.label[v] = self.label[u]\n",
    "                    heapq.heappush(pq, [self.cost[v], v])\n",
    "        self.ordered_nodes = [(u, self.cost[u]) for u in range(n)]\n",
    "        self.ordered_nodes.sort(key=itemgetter(1))\n",
    "                    \n",
    "    def _classify_one_vertex(self, x):\n",
    "        best_index, best_cost = self.ordered_nodes[0]\n",
    "        best_cost = max(best_cost, self.F(self.X[best_index], x))\n",
    "        best_label = self.label[best_index]\n",
    "        \n",
    "        for i in range(1, len(self.X)):\n",
    "            cur_index, cur_cost = self.ordered_nodes[i]\n",
    "            if cur_cost > best_cost:\n",
    "                break\n",
    "            cur_cost = max(cur_cost, self.F(self.X[cur_index], x))\n",
    "            cur_label = self.label[cur_index]\n",
    "            if cur_cost < best_cost:\n",
    "                best_index, best_cost, best_label = cur_index, cur_cost, cur_label\n",
    "        return best_label\n",
    "    \n",
    "    def classify(self, X_):\n",
    "        X_train = np.array(X_, copy=True)\n",
    "        return [self._classify_one_vertex(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584590da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordSynonyms (1.04s):\n",
      ">> OPF error: 0.400\n",
      ">> ED (w=0) error: 0.382\n",
      "\n",
      "ChlorineConcentration (7.61s):\n",
      ">> OPF error: 0.355\n",
      ">> ED (w=0) error: 0.350\n",
      "\n",
      "ShapesAll (4.04s):\n",
      ">> OPF error: 0.262\n",
      ">> ED (w=0) error: 0.248\n",
      "\n",
      "EthanolLevel (12.29s):\n",
      ">> OPF error: 0.726\n",
      ">> ED (w=0) error: 0.726\n",
      "\n",
      "FordA (126.33s):\n",
      ">> OPF error: 0.367\n",
      ">> ED (w=0) error: 0.335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_names = ['WordSynonyms', 'ChlorineConcentration', 'ShapesAll', 'EthanolLevel', 'FordA']\n",
    "for df_name in df_names:\n",
    "    X, y, X_test, y_test, dataset_error = read_df(df_name)\n",
    "    \n",
    "    start_time = time()\n",
    "    opf = OptimumPathForestClassifierPrim('euclidean-distance')\n",
    "    opf.fit(X, y)\n",
    "    preds = opf.classify(X_test)\n",
    "    print(\"%s (%.2fs):\" % (df_name, time() - start_time))\n",
    "    print(\">> OPF error: %.3f\" % error(preds, y_test))\n",
    "    print(\">> ED (w=0) error: %.3f\" % dataset_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf661363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prototypes_with_kruskal(adj, Y):\n",
    "    from src.OPFClassifier import DSU\n",
    "    n = len(Y)\n",
    "    \n",
    "    prototypes = []\n",
    "    edges = []\n",
    "    for u in range(n):\n",
    "        edges += [(w, u, v) for v, w in adj[u]]\n",
    "    edges.sort()\n",
    "    dsu = DSU(n)\n",
    "    for w, u, v in edges:\n",
    "        if not dsu.same(u, v):\n",
    "            dsu.merge(u, v)\n",
    "            if Y[u] != Y[v]:\n",
    "                prototypes += [u, v]\n",
    "    return np.unique(prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abd1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_test, y_test, dataset_error = read_df('WordSynonyms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c65986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3996865203761755"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opf = OptimumPathForestClassifierPrim('euclidean-distance')\n",
    "opf.fit(X, y)\n",
    "preds = opf.classify(X_test)\n",
    "error(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a139e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3871473354231975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opf = OptimumPathForestClassifierPrim('euclidean-distance')\n",
    "opf.find_prototypes = find_prototypes_with_kruskal\n",
    "opf.fit(X, y)\n",
    "preds = opf.classify(X_test)\n",
    "error(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5b509",
   "metadata": {},
   "source": [
    "### Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc4261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optimum Path Forest Classifier\"\"\"\n",
    "class OptimumPathForestClassifierLabelPropagation:    \n",
    "    def __init__(self, cost='euclidean-distance'):\n",
    "        available_cost_functions = {\n",
    "            'euclidean-distance': lambda x, y: np.linalg.norm(x - y),\n",
    "            'manhattan-distance': lambda x, y: np.sum(np.abs(x - y)),\n",
    "            'dtw-distance': lambda x, y: dtw.distance_fast(x, y, window=100, use_pruning=True)\n",
    "        }\n",
    "        assert cost in available_cost_functions.keys(),\\\n",
    "            f\"Invalid cost function. Should be one of {available_cost_functions.keys()}\"\n",
    "        self.F = available_cost_functions[cost]\n",
    "    \n",
    "    def find_prototypes(self, adj, Y):\n",
    "        from src.OPFClassifier import DSU\n",
    "        n = len(Y)\n",
    "\n",
    "        prototypes = []\n",
    "        edges = []\n",
    "        for u in range(n):\n",
    "            edges += [(w, u, v) for v, w in adj[u]]\n",
    "        edges.sort()\n",
    "        dsu = DSU(n)\n",
    "        for w, u, v in edges:\n",
    "            if not dsu.same(u, v):\n",
    "                dsu.merge(u, v)\n",
    "                if Y[u] != Y[v]:\n",
    "                    prototypes += [u, v]\n",
    "        return np.unique(prototypes)\n",
    "    \n",
    "    def fit(self, X_, Y_):\n",
    "        n = len(Y_)\n",
    "        self.X = np.array(X_, copy=True, dtype=float)\n",
    "        self.label = np.ones(n, dtype=int) * -1\n",
    "        Y = np.array(Y_, copy=True, dtype=int)\n",
    "        \n",
    "        # First of all, builds the graph\n",
    "        adj = defaultdict(list)\n",
    "        for u in range(n):\n",
    "            adj[u] = [(int(v), self.F(self.X[u], self.X[v])) for v in range(n)]\n",
    "            \n",
    "        # Runs MST (Prim) to choose PROTOTYPES (seed vertices)\n",
    "        self.prototypes = self.find_prototypes(adj, Y)\n",
    "        \n",
    "        # Run multisourced dijkstra on prototypes to get the cost\n",
    "        self.cost = np.ones(n) * np.inf\n",
    "        self.cost[self.prototypes] = 0\n",
    "        self.label[self.prototypes] = Y[self.prototypes]\n",
    "        \n",
    "        # Uses LabelPropagation\n",
    "        from sklearn.semi_supervised import LabelPropagation\n",
    "        self.label_prop_model = LabelPropagation()\n",
    "        self.label_prop_model.fit(X_, self.label)\n",
    "        self.label = self.label_prop_model.predict(X)\n",
    "    \n",
    "    def classify(self, X_):\n",
    "        return self.label_prop_model.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843dc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/AndreFakhoury/Documents/GitHub/time-series-opf/venv/lib/python3.8/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/mnt/c/Users/AndreFakhoury/Documents/GitHub/time-series-opf/venv/lib/python3.8/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7539184952978056, 0.3824)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, X_test, y_test, dataset_error = read_df('WordSynonyms')\n",
    "opf = OptimumPathForestClassifierLabelPropagation('euclidean-distance')\n",
    "opf.fit(X, y)\n",
    "preds = opf.classify(X_test)\n",
    "error(preds, y_test), dataset_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dc147e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optimum Path Forest Classifier\"\"\"\n",
    "class OptimumPathForestClassifierLabelAndEdges:    \n",
    "    def __init__(self, cost='euclidean-distance'):\n",
    "        available_cost_functions = {\n",
    "            'euclidean-distance': lambda x, y: np.linalg.norm(x - y),\n",
    "            'manhattan-distance': lambda x, y: np.sum(np.abs(x - y)),\n",
    "            'dtw-distance': lambda x, y: dtw.distance_fast(x, y, window=100, use_pruning=True)\n",
    "        }\n",
    "        assert cost in available_cost_functions.keys(),\\\n",
    "            f\"Invalid cost function. Should be one of {available_cost_functions.keys()}\"\n",
    "        self.F = available_cost_functions[cost]\n",
    "    \n",
    "    def find_prototypes(self, adj, Y):\n",
    "        from src.OPFClassifier import DSU\n",
    "        n = len(Y)\n",
    "\n",
    "        prototypes = []\n",
    "        edges = []\n",
    "        for u in range(n):\n",
    "            edges += [(w, u, v) for v, w in adj[u]]\n",
    "        edges.sort()\n",
    "        dsu = DSU(n)\n",
    "        for w, u, v in edges:\n",
    "            if not dsu.same(u, v):\n",
    "                dsu.merge(u, v)\n",
    "                if Y[u] != Y[v]:\n",
    "                    prototypes += [u, v]\n",
    "        return np.unique(prototypes)\n",
    "    \n",
    "    def fit(self, X_, Y_):\n",
    "        n = len(Y_)\n",
    "        self.X = np.array(X_, copy=True, dtype=float)\n",
    "        self.label = np.ones(n, dtype=int) * -1\n",
    "        Y = np.array(Y_, copy=True, dtype=int)\n",
    "        \n",
    "        # First of all, builds the graph\n",
    "        adj = defaultdict(list)\n",
    "        for u in range(n):\n",
    "            adj[u] = [(int(v), self.F(self.X[u], self.X[v])) for v in range(n)]\n",
    "            \n",
    "        # Runs MST (Prim) to choose PROTOTYPES (seed vertices)\n",
    "        self.prototypes = self.find_prototypes(adj, Y)\n",
    "        \n",
    "        # Run multisourced dijkstra on prototypes to get the cost\n",
    "        self.cost = np.ones(n) * np.inf\n",
    "        self.cost[self.prototypes] = 0\n",
    "        self.label[self.prototypes] = Y[self.prototypes]\n",
    "        \n",
    "        # Uses LabelPropagation\n",
    "        from sklearn.semi_supervised import LabelPropagation\n",
    "        self.label_prop_model = LabelPropagation()\n",
    "        self.label_prop_model.fit(X_, self.label)\n",
    "        self.label = self.label_prop_model.predict(X)\n",
    "        \n",
    "        pq = [[0., u] for u in self.prototypes]\n",
    "        heapq.heapify(pq)\n",
    "        while pq:\n",
    "            u_w, u = heapq.heappop(pq)\n",
    "            if self.cost[u] < u_w:\n",
    "                continue\n",
    "            for v, w in adj[u]:\n",
    "                if self.cost[v] > max(u_w, w):\n",
    "                    self.cost[v] = max(u_w, w)\n",
    "                    heapq.heappush(pq, [self.cost[v], v])\n",
    "        self.ordered_nodes = [(u, self.cost[u]) for u in range(n)]\n",
    "        self.ordered_nodes.sort(key=itemgetter(1))\n",
    "                    \n",
    "    def _classify_one_vertex(self, x):\n",
    "        best_index, best_cost = self.ordered_nodes[0]\n",
    "        best_cost = max(best_cost, self.F(self.X[best_index], x))\n",
    "        best_label = self.label[best_index]\n",
    "        \n",
    "        for i in range(1, len(self.X)):\n",
    "            cur_index, cur_cost = self.ordered_nodes[i]\n",
    "            if cur_cost > best_cost:\n",
    "                break\n",
    "            cur_cost = max(cur_cost, self.F(self.X[cur_index], x))\n",
    "            cur_label = self.label[cur_index]\n",
    "            if cur_cost < best_cost:\n",
    "                best_index, best_cost, best_label = cur_index, cur_cost, cur_label\n",
    "        return best_label\n",
    "    \n",
    "    def classify(self, X_):\n",
    "        X_train = np.array(X_, copy=True)\n",
    "        return [self._classify_one_vertex(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9a5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/AndreFakhoury/Documents/GitHub/time-series-opf/venv/lib/python3.8/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4717868338557994, 0.3824)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, X_test, y_test, dataset_error = read_df('WordSynonyms')\n",
    "opf = OptimumPathForestClassifierLabelAndEdges('euclidean-distance')\n",
    "opf.fit(X, y)\n",
    "preds = opf.classify(X_test)\n",
    "error(preds, y_test), dataset_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3cacbe",
   "metadata": {},
   "source": [
    "### kNN Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45078bea",
   "metadata": {},
   "source": [
    "https://repositorio.unesp.br/bitstream/handle/11449/162543/WOS000395616700015.pdf;jsessionid=52EED67B39AEB94C8FCC8863C3385821?sequence=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a13300d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optimum Path Forest Classifier\"\"\"\n",
    "class OptimumPathForestClassifierKNN:    \n",
    "    def __init__(self, cost='euclidean-distance'):\n",
    "        available_cost_functions = {\n",
    "            'euclidean-distance': lambda x, y: np.linalg.norm(x - y),\n",
    "            'manhattan-distance': lambda x, y: np.sum(np.abs(x - y)),\n",
    "            'dtw-distance': lambda x, y: dtw.distance_fast(x, y, window=100, use_pruning=True)\n",
    "        }\n",
    "        assert cost in available_cost_functions.keys(),\\\n",
    "            f\"Invalid cost function. Should be one of {available_cost_functions.keys()}\"\n",
    "        self.F = available_cost_functions[cost]\n",
    "        \n",
    "    def fit(self, X_, Y_, k=None):\n",
    "        n = len(Y_)\n",
    "        self.X = np.array(X_, copy=True, dtype=float)\n",
    "        Y = np.array(Y_, copy=True, dtype=int)\n",
    "        \n",
    "        if not k or k > n - 1:\n",
    "            k = n - 1\n",
    "\n",
    "        # First of all, builds the graph\n",
    "        adj = defaultdict(list)\n",
    "        dist = defaultdict(list)\n",
    "        \n",
    "        sigma = 0\n",
    "        for u in range(n):\n",
    "            dist[u] = [(int(v), self.F(self.X[u], self.X[v])) for v in range(n) if v != u]\n",
    "            adj[u] = dist[u]\n",
    "            adj[u].sort(key=itemgetter(1))\n",
    "            adj[u] = adj[u][:k]\n",
    "            sigma = max(sigma, adj[u][-1][1] / 3)\n",
    "        rho = np.zeros(n)\n",
    "        for s in range(n):\n",
    "            for v, w in adj[s]:\n",
    "                rho[s] += np.exp(-w**2 / (2 * sigma**2))\n",
    "            rho[s] *= 1 / (np.sqrt(2 * np.pi * sigma**2) * k)\n",
    "        \n",
    "        C = [rho[s]-1 for s in range(n)]\n",
    "        P = np.ones(n, dtype=int) * -1\n",
    "        L = Y\n",
    "        \n",
    "        pq = [(-C[u], u) for u in range(n)]\n",
    "        heapq.heapify(pq)\n",
    "        while pq:\n",
    "            u_c, u = heapq.heappop(pq)\n",
    "            if C[u] < -u_c:\n",
    "                continue\n",
    "            if P[u] == -1:\n",
    "                C[u] = rho[u]\n",
    "            for v, w in adj[u]:\n",
    "                tmp = w\n",
    "                if tmp > C[v]:\n",
    "                    L[v] = L[u]\n",
    "                    P[u] = s\n",
    "                    C[v] = tmp\n",
    "                    heapq.heappush(pq, (-C[v], v))\n",
    "        self.L, self.C, self.rho, self.k = L, C, rho, k\n",
    "                    \n",
    "    def _classify_one_vertex(self, x):\n",
    "        adj = [(v, self.F(x, self.X[v])) for v in range(len(self.X))]\n",
    "        adj.sort(key=itemgetter(1))\n",
    "        adj = adj[:self.k]\n",
    "        \n",
    "        C = [(min(self.C[v], self.rho[v]), v) for v, w in adj]\n",
    "        C.sort(reverse=True)\n",
    "        return self.L[C[0][1]]\n",
    "    \n",
    "    def classify(self, X_):\n",
    "        X_train = np.array(X_, copy=True)\n",
    "        return [self._classify_one_vertex(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2360a2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9764890282131662\n",
      "10 0.780564263322884\n",
      "20 0.7789968652037618\n",
      "50 0.780564263322884\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test, y_test, dataset_error = read_df('WordSynonyms')\n",
    "prev = -1\n",
    "for k in [0, 10, 20, 50, 100, 150, 170]:\n",
    "    opf = OptimumPathForestClassifierKNN('euclidean-distance')\n",
    "    opf.fit(X, y, k=k)\n",
    "    preds = opf.classify(X_test)\n",
    "    cur = error(preds, y_test)\n",
    "    if prev != cur:\n",
    "        print(k, cur)\n",
    "    prev = cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8365ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinatown (0.05830903790087463, 0)\n",
      "SonyAIBORobotSurface1 (0.3410981697171381, 0)\n",
      "ItalyPowerDemand (0.04956268221574344, 0)\n",
      "MoteStrain (0.11980830670926518, 0)\n",
      "SonyAIBORobotSurface2 (0.14060860440713535, 0)\n",
      "TwoLeadECG (0.25021949078138717, 0)\n",
      "SmoothSubspace (0.05333333333333334, 0)\n",
      "ECGFiveDays (0.2032520325203252, 0)\n",
      "Fungi (0.16129032258064516, 0)\n",
      "BME (0.17333333333333334, 0)\n",
      "CBF (0.21666666666666667, 0)\n",
      "UMD (0.20833333333333334, 0)\n",
      "DiatomSizeReduction (0.06535947712418301, 0)\n",
      "DodgerLoopGame (0.4782608695652174, 0)\n",
      "DodgerLoopWeekend (0.2608695652173913, 0)\n",
      "GunPoint (0.08, 0)\n",
      "Coffee (0.0, 0)\n",
      "FaceFour (0.22727272727272727, 10)\n",
      "FreezerSmallTrain (0.32421052631578945, 0)\n",
      "ArrowHead (0.2057142857142857, 20)\n",
      "ECG200 (0.11, 0)\n",
      "Symbols (0.10050251256281408, 0)\n",
      "ShapeletSim (0.5, 0)\n",
      "InsectEPGSmallTrain (0.0, 0)\n",
      "BeetleFly (0.25, 0)\n",
      "BirdChicken (0.45, 0)\n",
      "ToeSegmentation1 (0.30701754385964913, 0)\n",
      "ToeSegmentation2 (0.2076923076923077, 0)\n",
      "Wine (0.3888888888888889, 0)\n",
      "Beef (0.3333333333333333, 0)\n",
      "Plane (0.0380952380952381, 0)\n",
      "OliveOil (0.13333333333333333, 0)\n",
      "SyntheticControl (0.1, 10)\n",
      "GunPointAgeSpan (0.03164556962025317, 0)\n",
      "GunPointMaleVersusFemale (0.006329113924050633, 0)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m170\u001b[39m]:\n\u001b[1;32m     21\u001b[0m     opf \u001b[38;5;241m=\u001b[39m OptimumPathForestClassifierKNN(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean-distance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mopf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     preds \u001b[38;5;241m=\u001b[39m opf\u001b[38;5;241m.\u001b[39mclassify(X_test)\n\u001b[1;32m     24\u001b[0m     cur \u001b[38;5;241m=\u001b[39m error(preds, y_test)\n",
      "Cell \u001b[0;32mIn [29], line 47\u001b[0m, in \u001b[0;36mOptimumPathForestClassifierKNN.fit\u001b[0;34m(self, X_, Y_, k)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Run multisourced dijkstra on prototypes to get the cost\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprototypes\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes] \u001b[38;5;241m=\u001b[39m Y[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes]\n\u001b[1;32m     50\u001b[0m pq \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0.\u001b[39m, u] \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes]\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "from functools import cmp_to_key\n",
    "from os import listdir\n",
    "\n",
    "def get_val(a):\n",
    "    datasets_df = pd.read_csv('data/DataSummary.csv')\n",
    "    df_a = datasets_df.loc[datasets_df['Name'] == a].iloc[:,[3,6]]\n",
    "    val_a1 = df_a.values[0][0] if len(df_a.values) else 100000000\n",
    "    val_a2 = int(df_a.values[0][1]) if len(df_a.values) and df_a.values[0][1].isnumeric() else 100000000\n",
    "    return val_a1 * val_a2\n",
    "\n",
    "df_names = listdir('data/UCRArchive_2018')\n",
    "df_values = [(get_val(df_name), df_name) for df_name in df_names]\n",
    "\n",
    "df_values.sort()\n",
    "df_names = [df_name for val, df_name in df_values if val < 3e5]\n",
    "\n",
    "for df_name in df_names:\n",
    "    X, y, X_test, y_test, dataset_error = read_df(df_name)\n",
    "    best = (1e9, -1)\n",
    "    for k in [0, 10, 20, 50, 100, 150, 170]:\n",
    "        opf = OptimumPathForestClassifierKNN('euclidean-distance')\n",
    "        opf.fit(X, y, k=k)\n",
    "        preds = opf.classify(X_test)\n",
    "        cur = error(preds, y_test)\n",
    "        best = min(best, (cur, k))\n",
    "    print(df_name, best, dataset_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86eb020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "83ecd3fc6cc92009657adecd157b6521a55ff669669492e633028c095ba52787"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
