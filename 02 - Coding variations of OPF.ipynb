{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b26fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from src.OPFClassifier import DSU\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from dtaidistance import dtw\n",
    "from src.utils import error\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c7dbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.116105</td>\n",
       "      <td>-1.064810</td>\n",
       "      <td>-1.037813</td>\n",
       "      <td>-1.005432</td>\n",
       "      <td>-0.967361</td>\n",
       "      <td>-0.926633</td>\n",
       "      <td>-0.885112</td>\n",
       "      <td>-0.843260</td>\n",
       "      <td>-0.802281</td>\n",
       "      <td>-0.765167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>-0.107153</td>\n",
       "      <td>-0.218689</td>\n",
       "      <td>-0.330607</td>\n",
       "      <td>-0.446418</td>\n",
       "      <td>-0.567254</td>\n",
       "      <td>-0.688438</td>\n",
       "      <td>-0.805846</td>\n",
       "      <td>-0.909509</td>\n",
       "      <td>-0.990730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.003598</td>\n",
       "      <td>0.297771</td>\n",
       "      <td>0.314203</td>\n",
       "      <td>0.340310</td>\n",
       "      <td>0.360485</td>\n",
       "      <td>0.366483</td>\n",
       "      <td>0.367091</td>\n",
       "      <td>0.375067</td>\n",
       "      <td>0.389692</td>\n",
       "      <td>0.399434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977561</td>\n",
       "      <td>0.877289</td>\n",
       "      <td>0.775271</td>\n",
       "      <td>0.685158</td>\n",
       "      <td>0.593500</td>\n",
       "      <td>0.502324</td>\n",
       "      <td>0.422849</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>0.342001</td>\n",
       "      <td>0.326981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.260736</td>\n",
       "      <td>-2.258724</td>\n",
       "      <td>-2.226218</td>\n",
       "      <td>-2.221851</td>\n",
       "      <td>-2.222243</td>\n",
       "      <td>-2.220001</td>\n",
       "      <td>-2.214589</td>\n",
       "      <td>-2.206155</td>\n",
       "      <td>-2.195612</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.750738</td>\n",
       "      <td>-1.750414</td>\n",
       "      <td>-1.750161</td>\n",
       "      <td>-1.750388</td>\n",
       "      <td>-1.751637</td>\n",
       "      <td>-1.761790</td>\n",
       "      <td>-1.781287</td>\n",
       "      <td>-1.813242</td>\n",
       "      <td>-1.989937</td>\n",
       "      <td>-2.189689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.187217</td>\n",
       "      <td>-1.183150</td>\n",
       "      <td>-1.172870</td>\n",
       "      <td>-1.126120</td>\n",
       "      <td>-1.101117</td>\n",
       "      <td>-1.057204</td>\n",
       "      <td>-1.016442</td>\n",
       "      <td>-0.984648</td>\n",
       "      <td>-0.955151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778291</td>\n",
       "      <td>-0.792408</td>\n",
       "      <td>-0.821748</td>\n",
       "      <td>-0.838169</td>\n",
       "      <td>-0.856748</td>\n",
       "      <td>-0.895335</td>\n",
       "      <td>-0.932915</td>\n",
       "      <td>-1.008489</td>\n",
       "      <td>-1.071877</td>\n",
       "      <td>-1.133381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>-1.000660</td>\n",
       "      <td>-0.978911</td>\n",
       "      <td>-0.957183</td>\n",
       "      <td>-0.931947</td>\n",
       "      <td>-0.901690</td>\n",
       "      <td>-0.866264</td>\n",
       "      <td>-0.836568</td>\n",
       "      <td>-0.805765</td>\n",
       "      <td>-0.781656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292878</td>\n",
       "      <td>-0.359844</td>\n",
       "      <td>-0.435772</td>\n",
       "      <td>-0.506780</td>\n",
       "      <td>-0.589579</td>\n",
       "      <td>-0.670793</td>\n",
       "      <td>-0.743282</td>\n",
       "      <td>-0.817052</td>\n",
       "      <td>-0.878975</td>\n",
       "      <td>-0.942861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>-0.861169</td>\n",
       "      <td>-0.818737</td>\n",
       "      <td>-0.807341</td>\n",
       "      <td>-0.785858</td>\n",
       "      <td>-0.761313</td>\n",
       "      <td>-0.734760</td>\n",
       "      <td>-0.709592</td>\n",
       "      <td>-0.677477</td>\n",
       "      <td>-0.647337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544046</td>\n",
       "      <td>0.402501</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>0.036733</td>\n",
       "      <td>-0.163714</td>\n",
       "      <td>-0.368679</td>\n",
       "      <td>-0.509985</td>\n",
       "      <td>-0.639358</td>\n",
       "      <td>-0.730808</td>\n",
       "      <td>-0.788201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>-0.529065</td>\n",
       "      <td>0.392315</td>\n",
       "      <td>1.499541</td>\n",
       "      <td>2.117332</td>\n",
       "      <td>2.164945</td>\n",
       "      <td>1.832347</td>\n",
       "      <td>1.434090</td>\n",
       "      <td>1.212975</td>\n",
       "      <td>1.225051</td>\n",
       "      <td>...</td>\n",
       "      <td>3.410901</td>\n",
       "      <td>2.592988</td>\n",
       "      <td>2.246816</td>\n",
       "      <td>2.166496</td>\n",
       "      <td>1.964850</td>\n",
       "      <td>1.563155</td>\n",
       "      <td>1.576978</td>\n",
       "      <td>1.954937</td>\n",
       "      <td>2.061931</td>\n",
       "      <td>1.653530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5    \\\n",
       "count  267.000000  267.000000  267.000000  267.000000  267.000000  267.000000   \n",
       "mean     9.116105   -1.064810   -1.037813   -1.005432   -0.967361   -0.926633   \n",
       "std      7.003598    0.297771    0.314203    0.340310    0.360485    0.366483   \n",
       "min      1.000000   -2.260736   -2.258724   -2.226218   -2.221851   -2.222243   \n",
       "25%      3.000000   -1.187217   -1.183150   -1.172870   -1.126120   -1.101117   \n",
       "50%      8.000000   -1.000660   -0.978911   -0.957183   -0.931947   -0.901690   \n",
       "75%     14.000000   -0.861169   -0.818737   -0.807341   -0.785858   -0.761313   \n",
       "max     25.000000   -0.529065    0.392315    1.499541    2.117332    2.164945   \n",
       "\n",
       "              6           7           8           9    ...         261  \\\n",
       "count  267.000000  267.000000  267.000000  267.000000  ...  267.000000   \n",
       "mean    -0.885112   -0.843260   -0.802281   -0.765167  ...   -0.004913   \n",
       "std      0.367091    0.375067    0.389692    0.399434  ...    0.977561   \n",
       "min     -2.220001   -2.214589   -2.206155   -2.195612  ...   -1.750738   \n",
       "25%     -1.057204   -1.016442   -0.984648   -0.955151  ...   -0.778291   \n",
       "50%     -0.866264   -0.836568   -0.805765   -0.781656  ...   -0.292878   \n",
       "75%     -0.734760   -0.709592   -0.677477   -0.647337  ...    0.544046   \n",
       "max      1.832347    1.434090    1.212975    1.225051  ...    3.410901   \n",
       "\n",
       "              262         263         264         265         266         267  \\\n",
       "count  267.000000  267.000000  267.000000  267.000000  267.000000  267.000000   \n",
       "mean    -0.107153   -0.218689   -0.330607   -0.446418   -0.567254   -0.688438   \n",
       "std      0.877289    0.775271    0.685158    0.593500    0.502324    0.422849   \n",
       "min     -1.750414   -1.750161   -1.750388   -1.751637   -1.761790   -1.781287   \n",
       "25%     -0.792408   -0.821748   -0.838169   -0.856748   -0.895335   -0.932915   \n",
       "50%     -0.359844   -0.435772   -0.506780   -0.589579   -0.670793   -0.743282   \n",
       "75%      0.402501    0.223014    0.036733   -0.163714   -0.368679   -0.509985   \n",
       "max      2.592988    2.246816    2.166496    1.964850    1.563155    1.576978   \n",
       "\n",
       "              268         269         270  \n",
       "count  267.000000  267.000000  267.000000  \n",
       "mean    -0.805846   -0.909509   -0.990730  \n",
       "std      0.367574    0.342001    0.326981  \n",
       "min     -1.813242   -1.989937   -2.189689  \n",
       "25%     -1.008489   -1.071877   -1.133381  \n",
       "50%     -0.817052   -0.878975   -0.942861  \n",
       "75%     -0.639358   -0.730808   -0.788201  \n",
       "max      1.954937    2.061931    1.653530  \n",
       "\n",
       "[8 rows x 271 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_name = 'WordSynonyms'\n",
    "\n",
    "df = pd.read_table(f'data/UCRArchive_2018/{df_name}/{df_name}_TRAIN.tsv', header=None)\n",
    "df_test = pd.read_table(f'data/UCRArchive_2018/{df_name}/{df_name}_TEST.tsv', header=None)\n",
    "datasets_df = pd.read_csv('data/DataSummary.csv')\n",
    "\n",
    "X, Y = df.iloc[:, 1:], df.iloc[:, 0]\n",
    "X_test, Y_test = df_test.iloc[:, 1:], df_test.iloc[:, 0]\n",
    "dataset_error = datasets_df.loc[datasets_df['Name'] == df_name].iloc[:, 7].values[0]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dce8109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 14, 4, 14, 9, 2, 14, 4, 2, 20, 4, 2, 6, 21, 9, 22, 10, 7, 2, 2, 18, 22, 11, 4, 14, 6, 4, 13, 2, 6, 12, 4, 2, 22, 2, 2, 6, 4, 18, 23, 2, 18, 20, 24, 11, 16, 4, 2, 22, 4, 1, 20, 1, 21, 12, 8, 8, 24, 2, 23, 4, 21, 8, 2, 2, 13, 4, 14, 4, 2, 4, 22, 10, 11, 6, 14, 8, 19, 2, 18, 8, 2, 8, 4, 4, 4, 8, 21, 6, 4, 12, 2, 8, 2, 23, 4, 6, 8, 2, 9, 4, 10, 2, 11, 20, 11, 2, 2, 10, 4, 4, 4, 11, 22, 8, 6, 14, 2, 8, 14, 6, 22, 6, 14, 4, 21, 14, 2, 8, 12, 2, 4, 2, 8, 22, 22, 18, 9, 6, 4, 2, 18, 13, 4, 6, 4, 10, 2, 2, 10, 2, 4, 2, 9, 2, 8, 2, 2, 22, 6, 4, 16, 1, 4, 2, 4, 11, 2, 16, 14, 2, 2, 8, 10, 2, 4, 4, 2, 15, 2, 4, 8, 14, 23, 4, 2, 16, 12, 2, 4, 10, 14, 8, 11, 2, 4, 4, 2, 4, 2, 2, 4, 4, 22, 4, 11, 4, 24, 16, 2, 16, 2, 16, 4, 21, 10, 2, 8, 2, 10, 4, 5, 2, 18, 2, 2, 5, 2, 3, 17, 13, 16, 2, 14, 1, 4, 5, 10, 2, 8, 2, 2, 20, 4, 21, 8, 8, 2, 2, 6, 6, 18, 4, 4, 18, 24, 4, 6, 10, 11, 4, 23, 6, 4, 4, 2, 10, 2, 2, 4, 20, 2, 4, 2, 20, 6, 4, 1, 2, 1, 2, 12, 2, 6, 3, 6, 24, 10, 22, 9, 9, 2, 4, 20, 9, 6, 2, 16, 23, 6, 10, 8, 6, 8, 4, 2, 4, 2, 6, 4, 19, 2, 2, 4, 19, 9, 19, 14, 11, 2, 4, 16, 19, 4, 2, 8, 6, 2, 4, 2, 4, 4, 6, 10, 16, 13, 21, 12, 2, 6, 22, 10, 6, 6, 20, 6, 16, 14, 2, 8, 12, 2, 2, 2, 11, 14, 16, 16, 16, 2, 11, 12, 14, 6, 16, 4, 6, 6, 4, 14, 6, 8, 20, 2, 15, 16, 8, 3, 1, 10, 6, 16, 2, 12, 4, 9, 15, 4, 10, 17, 10, 4, 11, 2, 2, 4, 8, 2, 2, 8, 6, 2, 20, 16, 6, 15, 2, 4, 12, 9, 2, 12, 8, 2, 15, 4, 8, 19, 2, 2, 18, 4, 6, 2, 16, 21, 14, 4, 2, 2, 18, 1, 2, 24, 2, 21, 2, 2, 6, 2, 24, 16, 21, 23, 11, 2, 2, 4, 4, 8, 8, 2, 2, 6, 1, 2, 17, 6, 6, 4, 2, 8, 14, 4, 11, 11, 12, 9, 4, 11, 2, 21, 22, 22, 4, 2, 1, 2, 2, 14, 14, 4, 4, 2, 20, 12, 2, 15, 2, 10, 2, 4, 15, 14, 3, 5, 22, 2, 20, 2, 16, 2, 2, 22, 6, 10, 6, 1, 12, 8, 12, 5, 4, 4, 10, 15, 14, 2, 16, 2, 4, 1, 2, 2, 11, 4, 4, 18, 6, 16, 4, 2, 13, 10, 13, 10, 11, 17, 11, 2, 4, 2, 2, 10, 11, 2, 4, 2, 6, 14, 2, 4, 8, 8, 11, 7, 8, 4, 4, 14, 8, 4, 12, 18, 4, 2, 4, 4, 12, 2, 14, 4, 6, 6, 4, 15, 10, 2, 2, 4, 12, 8, 6, 10, 8, 19, 16, 8, 4, 15, 4, 2, 6, 2, 4, 22, 6, 10, 2, 8, 2, 9, 10, 2, 2, 2, 15, 2, 11, 2, 2, 20, 4, 2, 6, 2, 6, 17, 11, 2, 20, 25, 10, 2, 14, 4, 2, 4, 24, 8, 10, 24, 16, 6, 14, 19, 2]\n",
      "OPF error: 0.3871473354231975\n",
      "ED (w=0) error: 0.3824\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Optimum Path Forest Classifier\"\"\"\n",
    "class OptimumPathForestClassifier:    \n",
    "    def __init__(self, cost='euclidean-distance'):\n",
    "        available_cost_functions = {\n",
    "            'euclidean-distance': lambda x, y: np.linalg.norm(x - y),\n",
    "            'manhattan-distance': lambda x, y: np.sum(np.abs(x - y)),\n",
    "            'dtw-distance': lambda x, y: dtw.distance_fast(x, y, use_pruning=True)\n",
    "        }\n",
    "        assert cost in available_cost_functions.keys(),\\\n",
    "            f\"Invalid cost function. Should be one of {available_cost_functions.keys()}\"\n",
    "        self.F = available_cost_functions[cost]\n",
    "    \n",
    "    def fit(self, X_, Y_):\n",
    "        n = len(Y_)\n",
    "        self.X = np.array(X_, copy=True, dtype=float)\n",
    "        self.label = np.ones(n, dtype=int) * -1\n",
    "        Y = np.array(Y_, copy=True, dtype=int)\n",
    "        \n",
    "        # First of all, builds the graph\n",
    "        self.adj = defaultdict(list)\n",
    "        self.edges = []\n",
    "        for u in range(n):\n",
    "            self.adj[u] = [(v, self.F(self.X[u], self.X[v])) for v in range(n)]\n",
    "            self.edges += [(w, u, v) for v, w in self.adj[u]]\n",
    "        \n",
    "        # Runs MST (Kruskal) to choose PROTOTYPES (seed vertices)\n",
    "        self.prototypes = []        \n",
    "        self.edges.sort()\n",
    "        dsu = DSU(n)\n",
    "        for w, u, v in self.edges:\n",
    "            if not dsu.same(u, v):\n",
    "                dsu.merge(u, v)\n",
    "                if Y[u] != Y[v]:\n",
    "                    self.prototypes += [u, v]\n",
    "        self.prototypes = np.unique(self.prototypes)\n",
    "        \n",
    "        # Run multisourced dijkstra on prototypes to get the cost\n",
    "        self.cost = np.ones(n) * np.inf\n",
    "        self.cost[self.prototypes] = 0\n",
    "        self.label[self.prototypes] = Y[self.prototypes]\n",
    "        \n",
    "        pq = [[0., u] for u in self.prototypes]\n",
    "        heapq.heapify(pq)\n",
    "        while pq:\n",
    "            u_w, u = heapq.heappop(pq)\n",
    "            if self.cost[u] < u_w:\n",
    "                continue\n",
    "            for v, w in self.adj[u]:\n",
    "                if self.cost[v] > max(u_w, w):\n",
    "                    self.cost[v] = max(u_w, w)\n",
    "                    self.label[v] = self.label[u]\n",
    "                    heapq.heappush(pq, [self.cost[v], v])\n",
    "        self.ordered_nodes = [(u, self.cost[u]) for u in range(n)]\n",
    "        self.ordered_nodes.sort(key=itemgetter(1))\n",
    "                    \n",
    "    def _classify_one_vertex(self, x):\n",
    "        best_index, best_cost = self.ordered_nodes[0]\n",
    "        best_cost = max(best_cost, self.F(self.X[best_index], x))\n",
    "        best_label = self.label[best_index]\n",
    "        \n",
    "        for i in range(1, len(self.X)):\n",
    "            cur_index, cur_cost = self.ordered_nodes[i]\n",
    "            if cur_cost > best_cost:\n",
    "                break\n",
    "            cur_cost = max(cur_cost, self.F(self.X[cur_index], x))\n",
    "            cur_label = self.label[cur_index]\n",
    "            if cur_cost < best_cost:\n",
    "                best_index, best_cost, best_label = cur_index, cur_cost, cur_label\n",
    "        return best_label\n",
    "    \n",
    "    def classify(self, X_):\n",
    "        X_train = np.array(X_, copy=True)\n",
    "        return [self._classify_one_vertex(x) for x in X_train]\n",
    "    \n",
    "opf = OptimumPathForestClassifier('euclidean-distance')\n",
    "opf.fit(X, Y)\n",
    "preds = opf.classify(X_test)\n",
    "\n",
    "print(preds)\n",
    "print(f\"OPF error: {error(preds, Y_test)}\")\n",
    "print(f\"ED (w=0) error: {dataset_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584590da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-01 14:48:35,594 - opfython.models.supervised — INFO — Overriding class: OPF -> SupervisedOPF.\n",
      "2022-09-01 14:48:35,595 - opfython.core.opf — INFO — Creating class: OPF.\n",
      "2022-09-01 14:48:35,596 - opfython.core.opf — DEBUG — Distance: euclidean | Pre-computed distance: False.\n",
      "2022-09-01 14:48:35,596 - opfython.core.opf — INFO — Class created.\n",
      "2022-09-01 14:48:35,597 - opfython.models.supervised — INFO — Class overrided.\n",
      "2022-09-01 14:48:35,598 - opfython.models.supervised — INFO — Fitting classifier ...\n",
      "2022-09-01 14:48:35,601 - opfython.models.supervised — DEBUG — Finding prototypes ...\n",
      "2022-09-01 14:48:36,663 - opfython.models.supervised — DEBUG — Prototypes: [124, 0, 174, 118, 157, 186, 133, 126, 161, 10, 86, 199, 52, 37, 208, 88, 18, 262, 104, 218, 213, 45, 30, 65, 247, 108, 28, 230, 235, 100, 64, 85, 3, 142, 96, 31, 227, 200, 55, 111, 202, 212, 106, 251, 99, 180, 17, 183, 39, 229, 19, 146, 256, 63, 91, 128, 34, 169, 207, 40, 232, 259, 260, 264, 78, 46, 149, 22, 56, 210, 204, 103, 265, 61, 47, 222, 234, 144, 73, 173, 233, 170, 14, 249, 182, 261, 242, 32, 159, 109, 102, 122, 220, 137, 240, 198, 223, 238, 165, 27, 211, 151, 21, 127, 236, 191, 57, 82, 70, 134, 253, 214, 135, 219, 15, 81, 1, 107, 93, 24, 196, 123, 89, 257, 62, 168, 20, 7, 155, 225, 16, 143, 176, 177, 98, 114, 59, 152, 164, 9, 184, 95, 217, 245, 263, 116, 243, 244, 153, 150, 215, 131, 69, 58, 112, 129, 136, 252, 195, 43, 197, 36, 250, 50, 80, 194, 154, 25, 156, 141, 140, 205, 119, 49, 48, 76, 178, 90, 54, 216, 231, 110, 11].\n",
      "2022-09-01 14:48:36,775 - opfython.models.supervised — INFO — Classifier has been fitted.\n",
      "2022-09-01 14:48:36,776 - opfython.models.supervised — INFO — Training time: 1.1759428977966309 seconds.\n",
      "2022-09-01 14:48:36,777 - opfython.models.supervised — INFO — Predicting data ...\n",
      "2022-09-01 14:48:37,630 - opfython.models.supervised — INFO — Data has been predicted.\n",
      "2022-09-01 14:48:37,631 - opfython.models.supervised — INFO — Prediction time: 0.8522841930389404 seconds.\n",
      "[4, 12, 14, 4, 14, 9, 2, 14, 4, 2, 20, 4, 2, 6, 21, 9, 22, 10, 7, 2, 2, 18, 22, 11, 4, 14, 6, 4, 13, 2, 6, 12, 4, 2, 22, 2, 2, 6, 4, 18, 23, 2, 18, 20, 24, 11, 16, 4, 2, 22, 4, 1, 20, 1, 21, 12, 8, 8, 24, 2, 23, 4, 21, 8, 2, 2, 13, 4, 14, 4, 2, 4, 22, 10, 11, 6, 14, 8, 19, 2, 18, 8, 2, 8, 4, 4, 4, 8, 21, 6, 4, 12, 2, 8, 2, 23, 4, 6, 8, 2, 9, 4, 10, 2, 11, 20, 11, 2, 2, 10, 4, 4, 4, 11, 22, 8, 6, 14, 2, 8, 14, 6, 22, 6, 14, 4, 21, 14, 2, 8, 12, 2, 4, 2, 8, 22, 22, 18, 9, 6, 4, 2, 18, 13, 4, 6, 4, 10, 2, 2, 10, 2, 4, 2, 9, 2, 8, 2, 2, 22, 6, 4, 16, 1, 4, 2, 4, 11, 2, 16, 14, 2, 2, 8, 10, 2, 4, 4, 2, 15, 2, 4, 8, 14, 23, 4, 2, 16, 12, 2, 4, 10, 14, 8, 11, 2, 4, 4, 2, 4, 2, 2, 4, 4, 22, 4, 11, 4, 24, 16, 2, 16, 2, 16, 4, 21, 10, 2, 8, 2, 10, 4, 5, 2, 18, 2, 2, 5, 2, 3, 17, 13, 16, 2, 14, 1, 4, 5, 10, 2, 8, 2, 2, 20, 4, 21, 8, 8, 2, 2, 6, 6, 18, 4, 4, 18, 24, 4, 6, 10, 11, 4, 23, 6, 4, 4, 2, 10, 2, 2, 4, 20, 2, 4, 2, 20, 6, 4, 1, 2, 1, 2, 12, 2, 6, 3, 6, 24, 10, 22, 9, 9, 2, 4, 20, 9, 6, 2, 16, 23, 6, 10, 8, 6, 8, 4, 2, 4, 2, 6, 4, 19, 2, 2, 4, 19, 9, 19, 14, 11, 2, 4, 16, 19, 4, 2, 8, 6, 2, 4, 2, 4, 4, 6, 10, 16, 13, 21, 12, 2, 6, 22, 10, 6, 6, 20, 6, 16, 14, 2, 8, 12, 2, 2, 2, 11, 14, 16, 16, 16, 2, 11, 12, 14, 6, 16, 4, 6, 6, 4, 14, 6, 8, 20, 2, 15, 16, 8, 3, 1, 10, 6, 16, 2, 12, 4, 9, 15, 4, 10, 17, 10, 4, 11, 2, 2, 4, 8, 2, 2, 8, 6, 2, 20, 16, 6, 15, 2, 4, 12, 9, 2, 12, 8, 2, 15, 4, 8, 19, 2, 2, 18, 4, 6, 2, 16, 21, 14, 4, 2, 2, 18, 1, 2, 24, 2, 21, 2, 2, 6, 2, 24, 16, 21, 23, 11, 2, 2, 4, 4, 8, 8, 2, 2, 6, 1, 2, 17, 6, 6, 4, 2, 8, 14, 4, 11, 11, 12, 9, 4, 11, 2, 21, 22, 22, 4, 2, 1, 2, 2, 14, 14, 4, 4, 2, 20, 12, 2, 15, 2, 10, 2, 4, 15, 14, 3, 5, 22, 2, 20, 2, 16, 2, 2, 22, 6, 10, 6, 1, 12, 8, 12, 5, 4, 4, 10, 15, 14, 2, 16, 2, 4, 1, 2, 2, 11, 4, 4, 18, 6, 16, 4, 2, 13, 10, 13, 10, 11, 17, 11, 2, 4, 2, 2, 10, 11, 2, 4, 2, 6, 14, 2, 4, 8, 8, 11, 7, 8, 4, 4, 14, 8, 4, 12, 18, 4, 2, 4, 4, 12, 2, 14, 4, 6, 6, 4, 15, 10, 2, 2, 4, 12, 8, 6, 10, 8, 19, 16, 8, 4, 15, 4, 2, 6, 2, 4, 22, 6, 10, 2, 8, 2, 9, 10, 2, 2, 2, 15, 2, 11, 2, 2, 20, 4, 2, 6, 2, 6, 17, 11, 2, 20, 25, 10, 2, 14, 4, 2, 4, 24, 8, 10, 24, 16, 6, 14, 19, 2]\n",
      "OPF error: 0.3871473354231975\n"
     ]
    }
   ],
   "source": [
    "# Creates a SupervisedOPF instance\n",
    "from opfython.models import SupervisedOPF\n",
    "\n",
    "opf_2 = SupervisedOPF(distance=\"euclidean\", pre_computed_distance=None)\n",
    "\n",
    "# Fits training data into the classifier\n",
    "opf_2.fit(np.array(X, copy=True), np.array(Y, copy=True))\n",
    "\n",
    "# Predicts new data\n",
    "preds_2 = opf_2.predict(np.array(X_test, copy=True))\n",
    "print(preds_2)\n",
    "print(f\"OPF error: {error(preds_2, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760c286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "83ecd3fc6cc92009657adecd157b6521a55ff669669492e633028c095ba52787"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
